{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbdc8e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 15:02:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/10 15:02:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/12/10 15:02:52 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"24121001_SparkSQL_execution_plan\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c96240",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('data/emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82fef339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eabcc5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('data/dept.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34c0e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deptno: integer (nullable = true)\n",
      " |-- dname: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03ffb37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df.createOrReplaceTempView('emp_df_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3575d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_df.createOrReplaceTempView('dept_df_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbbea2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뷰에서 조인\n",
    "join_query = '''\n",
    "select *\n",
    "from emp_df_view join dept_df_view on emp_df_view.deptno = dept_df_view.deptno\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20eff30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|    30|     SALES| CHICAGO|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|    30|     SALES| CHICAGO|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|    30|     SALES| CHICAGO|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|    30|     SALES| CHICAGO|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|    30|     SALES| CHICAGO|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|    30|     SALES| CHICAGO|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "viewEmpDept = spark.sql(join_query)\n",
    "viewEmpDept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d93dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewEmpDept.createOrReplaceTempView('viewEmpDept')\n",
    "# 부서위치가 'NEW YORK' 인 직원 목록\n",
    "\n",
    "v_query = '''\n",
    "select *\n",
    "from viewEmpDept\n",
    "where loc = 'NEW YORK'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cb6aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case1\n",
    "spark.sql(v_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99b86347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subquery\n",
    "\n",
    "q2 = '''\n",
    "select *\n",
    "from emp_df_view\n",
    "where deptno = (\n",
    "    select deptno\n",
    "    from dept_df_view\n",
    "    where loc='NEW YORK'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29b6d3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case2\n",
    "spark.sql(q2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdd1da69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [deptno#166], [deptno#232], Inner, BuildRight, false\n",
      ":- *(2) Filter isnotnull(deptno#166)\n",
      ":  +- FileScan csv [empno#159,ename#160,job#161,mgr#162,hiredate#163,sal#164,comm#165,deptno#166] Batched: false, DataFilters: [isnotnull(deptno#166)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab15/src/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:int,ename:string,job:string,mgr:int,hiredate:string,sal:int,comm:int,deptno:int>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#546]\n",
      "   +- *(1) Filter ((isnotnull(loc#234) AND (loc#234 = NEW YORK)) AND isnotnull(deptno#232))\n",
      "      +- FileScan csv [deptno#232,dname#233,loc#234] Batched: false, DataFilters: [isnotnull(loc#234), (loc#234 = NEW YORK), isnotnull(deptno#232)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab15/src/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK), IsNotNull(deptno)], ReadSchema: struct<deptno:int,dname:string,loc:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case1 실행계획 join\n",
    "spark.sql(v_query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ec98044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(deptno#166) AND (deptno#166 = Subquery scalar-subquery#778, [id=#565]))\n",
      ":  +- Subquery scalar-subquery#778, [id=#565]\n",
      ":     +- *(1) Project [deptno#232]\n",
      ":        +- *(1) Filter (isnotnull(loc#234) AND (loc#234 = NEW YORK))\n",
      ":           +- FileScan csv [deptno#232,loc#234] Batched: false, DataFilters: [isnotnull(loc#234), (loc#234 = NEW YORK)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab15/src/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK)], ReadSchema: struct<deptno:int,loc:string>\n",
      "+- FileScan csv [empno#159,ename#160,job#161,mgr#162,hiredate#163,sal#164,comm#165,deptno#166] Batched: false, DataFilters: [isnotnull(deptno#166)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab15/src/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:int,ename:string,job:string,mgr:int,hiredate:string,sal:int,comm:int,deptno:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case2 실행계획 - 서브쿼리 / 훨씬 효과적으로 보임 필터로 좁히는 방식으로 진행\n",
    "spark.sql(q2).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3838d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2fa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

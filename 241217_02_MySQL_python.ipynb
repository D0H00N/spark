{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8b54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_ip=\"15.168.30.32\" #localhost\n",
    "user_id=\"spark_user\"\n",
    "user_password=\"1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73912e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--jars /usr/local/lib/mysql-connector-java-5.1.49-bin.jar pyspark-shell\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0cb2390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/17 13:40:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"mysqlconnect\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "407e64de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tue Dec 17 13:49:21 KST 2024 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n"
     ]
    }
   ],
   "source": [
    "mysql_url = f\"jdbc:mysql://{host_ip}:3306/my_db\"\n",
    "dept_df = spark.read.format(\"jdbc\").options(\n",
    "    url=mysql_url,\n",
    "    driver=\"com.mysql.jdbc.Driver\",\n",
    "    dbtable=\"DEPT\",\n",
    "    user=user_id,\n",
    "    password=user_password\n",
    ").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a4c094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "Tue Dec 17 13:49:44 KST 2024 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.\n",
      "\r",
      "[Stage 0:===========================================================(1 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+\n",
      "|DEPTNO|     DNAME|     LOC|\n",
      "+------+----------+--------+\n",
      "|    10|ACCOUNTING|NEW YORK|\n",
      "|    20|  RESEARCH|  DALLAS|\n",
      "|    40|OPERATIONS|  BOSTON|\n",
      "+------+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68b9af5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1643586529.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    select * from emp:\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# EMP, SALGRADE\n",
    "select * from emp:\n",
    "    \n",
    "select deptno, ename, sal, job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b979ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400bdb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     value|\n",
      "+----------+\n",
      "|Hello HDFS|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HDFS Test\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://localhost:9000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# HDFS 파일 읽기\n",
    "df = spark.read.text(\"hdfs://localhost:9000/test/testfile.txt\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088b4a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
